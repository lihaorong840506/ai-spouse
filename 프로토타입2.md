# 프로토타입2 설계서 - "존재감 부여"

## 개요
프로토타입1의 기본 대화 기능에 캐릭터 표정, 애니메이션, 음성(TTS) 기능을 추가하여 AI 배우자의 "존재감"을 부여합니다.

## 목표
- AI 답변에 따라 캐릭터가 표정을 짓고 애니메이션 재생
- AI 답변을 음성으로 출력 (TTS)
- 감정 분석 및 반영 시스템

---

## 기능 설계

### 1. 감정 분석 시스템 (EmotionAnalyzer)

**역할**: AI 답변에서 감정을 분석하고 태그를 추출

**기능**:
- AI 답변 텍스트 분석
- 감정 태그 추출: [happy], [sad], [angry], [surprised], [thinking], [neutral]
- 감정 강도 계산 (0~100)

**프롬프트 수정**:
- 시스템 프롬프트에 "답변 끝에 [감정] 태그를 붙여주세요" 지시 추가
- 예: "오늘 일하느라 고생했어요. [happy]"

---

### 2. 캐릭터 애니메이션 시스템 (CharacterAnimationController)

**역할**: 감정에 따른 캐릭터 애니메이션 제어

**기능**:
- 감정별 애니메이션 매핑
- Idle 상태 관리
- 전환 애니메이션 (blend tree 사용)

**감정별 애니메이션 매핑**:
| 감정 | 애니메이션 | 설명 |
|---|---|---|
| neutral | Idle | 기본 상태 |
| happy | Happy_Anim | 웃는 표정, 손뼉 |
| sad | Sad_Anim | 슬픈 표정, 고개 숙임 |
| angry | Angry_Anim | 화난 표정, 팔짱 |
| surprised | Surprised_Anim | 놀란 표정 |
| thinking | Thinking_Anim | 생각하는 표정, 손가락 턱 |

---

### 3. TTS (Text-to-Speech) 시스템 (TTSManager)

**역할**: 텍스트를 음성으로 변환하여 재생

**지원 옵션**:
1. **OpenAI TTS API** (추천)
   - Voice: `alloy`, `echo`, `fable`, `onyx`, `nova`, `shimmer`
   - Speed: 0.25 ~ 4.0
   - 감정에 따라 pitch/voice 변경 가능

2. **Unity TTS** (무료, 품질 낮음)
   - OS 기본 TTS 사용

**기능**:
- 텍스트에서 감정 태그 제거 후 TTS 전송
- 현재 재생 중인 음성 중지 기능
- 배경 음악과 볼륨 조절

---

### 4. 리포머 테스트 (Reformer Text) - Live2D용

**Live2D 사용 시**:
- 리포머 텍스트(대사)를 화면에 표시
- 타이핑 효과로 텍스트가 한 글자씩 나타남
- 감정에 따른 텍스트 색상 변경

---

## 아키텍처

```
┌─────────────────────────────────────────────────────────────┐
│                        ChatUI                                │
│  (입력창, 전송 버튼, 메시지 표시)                           │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                   ConversationManager                        │
│  (대화 관리, 페르소나 적용)                                  │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                     AzureOpenAIClient                        │
│  (API 호출, 응답 수신)                                      │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                    AI Response 처리                         │
└─────────────────────────────────────────────────────────────┘
         │                    │                    │
         ▼                    ▼                    ▼
┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│EmotionAnalyzer│    │TTSManager    │    │CharacterAnim │
│(감정 추출)    │    │(음성 재생)   │    │(애니메이션)  │
└──────────────┘    └──────────────┘    └──────────────┘
```

---

## 클래스 설계

### 1. EmotionType.cs
```csharp
public enum EmotionType
{
    Neutral,
    Happy,
    Sad,
    Angry,
    Surprised,
    Thinking
}
```

### 2. EmotionData.cs
```csharp
[System.Serializable]
public class EmotionData
{
    public EmotionType emotion;
    public int intensity; // 0~100
    public string rawText; // 감정 태그 제거된 텍스트
}
```

### 3. EmotionAnalyzer.cs
```csharp
public class EmotionAnalyzer : MonoBehaviour
{
    // AI 응답에서 감정 태그 추출
    public EmotionData AnalyzeEmotion(string response);

    // 태그 제거된 텍스트 반환
    public string RemoveEmotionTags(string response);
}
```

### 4. TTSManager.cs
```csharp
public class TTSManager : MonoBehaviour
{
    [Header("TTS 설정")]
    [SerializeField] private string openAIKey;
    [SerializeField] private string voiceName = "nova"; // 여성 목소리
    [SerializeField] private float defaultSpeed = 1.0f;

    // 텍스트를 음성으로 재생
    public async void SpeakText(string text, EmotionType emotion = EmotionType.Neutral);

    // 현재 재생 중지
    public void StopSpeaking();

    // 재생 중인지 확인
    public bool IsSpeaking();
}
```

### 5. CharacterAnimationController.cs
```csharp
public class CharacterAnimationController : MonoBehaviour
{
    [Header("애니메이션 설정")]
    [SerializeField] private Animator animator;
    [SerializeField] private float crossFadeDuration = 0.3f;

    // 감정에 맞는 애니메이션 재생
    public void PlayEmotionAnimation(EmotionType emotion, float intensity = 1.0f);

    // Idle 상태로 복귀
    public void ReturnToIdle();

    // 특정 애니메이션 재생
    public void PlayAnimation(string animationName);
}
```

### 6. Live2DController.cs (Live2D 사용 시)
```csharp
public class Live2DController : MonoBehaviour
{
    // Live2D 모델 참조
    // 표정 파라미터 제어

    public void SetEmotion(EmotionType emotion);
    public void UpdateTypingText(string text);
}
```

---

## 수정 필요 파일

### ConversationManager.cs 수정
- `OnAIResponseReceived` 이벤트로 전달되는 응답 처리
- 감정 분석 → 애니메이션 → TTS 순서로 실행

### 시스템 프롬프트 수정
- 감정 태그 사용 지시 추가

---

## 캐릭터 설정 (외부 에셋 사용)

### 캐릭터 소스

**1. Mixamo (추천 - 무료)**
- URL: https://www.mixamo.com
- Adobe 계정으로 로그인 후 사용
- 다양한 캐릭터와 애니메이션 제공

**2. Unity Asset Store**
- 추천 에셋:
  - UMA 2 (Universal Modular Avatar)
  - Toon Character Maker
  - Cartoon RPG Character Pack

**3. Live2D**
- 2D 캐릭터 애니메이션
- Live2D Cubism Editor 필요

### Mixamo 사용법

1. **캐릭터 선택**: Mixamo 라이브러리에서 캐릭터 선택
2. **애니메이션 선택**: 감정별 애니메이션 다운로드
   - Idle: Standing Idle
   - Happy: Happy Idle, Clapping
   - Sad: Sad Idle, Crying
   - Angry: Angry Idle
   - Surprised: Surprised, Shocked
   - Thinking: Thinking, Wondering
3. **Unity 임포트**: 다운로드한 .fbx 파일을 Unity로 임포트
4. **프리팹 생성**: 캐릭터 프리팹으로 저장
5. **CharacterSpawner에 할당**: 프리팹을 CharacterSpawner 컴포넌트에 할당

### Unity 설정

1. **CharacterSpawner 컴포넌트 추가**
   - `Character Prefab`에 다운로드한 캐릭터 프리팹 할당
   - `Spawn Point`에 캐릭터 생성 위치 설정
   - `Target Camera`에 메인 카메라 할당

2. **애니메이션 컨트롤러 설정**
   - 감정별 애니메이션을 Animator Controller에 등록
   - `AnimationNameMapping`에 애니메이션 이름 설정

### 캐릭터 클래스

#### CharacterSpawner.cs
- 캐릭터 프리팹을 생성
- CharacterAnimationController 자동 연결
- 카메라 설정

#### CharacterSetupGuide.cs
- 캐릭터 설정 방법 안내 (에디터 전용)

#### SimpleCharacterBuilder.cs
- 테스트용 간단한 기하학적 캐릭터
- 외부 에셋이 없을 때 사용

---

## 구현 순서

1. **EmotionAnalyzer 구현**
   - 감정 태그 파싱 로직 구현

2. **CharacterAnimationController 구현**
   - Animator 참조 및 애니메이션 매핑

3. **TTSManager 구현**
   - OpenAI TTS API 연동

4. **ConversationManager 수정**
   - 감정 분석 → 애니메이션 → TTS 파이프라인 연결

5. **캐릭터 설정**
   - Mixamo 또는 Asset Store에서 캐릭터 다운로드
   - CharacterSpawner에 프리팹 할당

6. **UI 업데이트**
   - 리포머 텍스트 표시 (Live2D 시)

---

## 프로토타입2 완료 기준

- [ ] AI 답변에 [happy], [sad] 등 감정 태그가 포함됨
- [ ] 감정 태그에 맞는 애니메이션이 재생됨
- [ ] AI 답변이 음성으로 출력됨 (TTS)
- [ ] 대화 중 음성 중단 가능
- [ ] 리포머 텍스트가 화면에 타이핑 효과로 표시됨
